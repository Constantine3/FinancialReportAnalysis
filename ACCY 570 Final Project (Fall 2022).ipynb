{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCY 570 Final Project\n",
    "### Fall 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final project contains 24 files: this Jupyter notebook and 23 data files. Twenty of the data files are PDF's containing company annual reports. Two of the data files are text files (*AuditAnalytics.txt* and *Compustat.txt*), and there is also an Excel file (*GatherAuditorData.xlsx*). We packaged these files as a ZIP file. *You must extract these files from the ZIP file in order to work with them.*\n",
    "\n",
    "You will do some of your work in this Jupyter notebook and some in Tableau. You may create additional cells in the notebook if you wish. \n",
    "\n",
    "When you have finished:\n",
    "\n",
    "1. Save your Tableau file as a Tableau Packaged Workbook (.twbx). This makes it much easier for us to grade.\n",
    "2. Do *not* combine your files into a ZIP or RAR file.\n",
    "3. Submit this Jupyter notebook and one Tableau workbook on Canvas.\n",
    "4. If you are working with a partner, please let me know. \n",
    "5. If you submit more than once, we will grade your most recent submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the final project for ACCY 570. \n",
    "\n",
    "The project has two parts. In part 1, you will load, clean, and analyze data about the audit industry. Specifically, you will examine the drivers of the fees charged by auditors. In part 2, you will use text analysis and automation to parse 10-K's in PDF format and compute auditor tenure.\n",
    "\n",
    "You have learned much this semester and in this project you will bring to bear much of your newfound knowledge and skills. However, when you perform analytics in the real world, you will often need to learn new skills. This project is no different. That's why we also spent time this semester talking about using the documentation for Python commands and using new libraries. You will learn a few things in this project that we did not directly teach you over the semester.\n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Drivers of Audit Fees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 1, you will examine the determinants and drivers of audit fees. You will work with real data on audit fees and client characteristics. First, you will load and clean the two datasets containing audit fees and client characteristics. Then you will *merge* these datasets. Finally, you will perform some analyses (e.g., descriptive statistics, scatter plots). \n",
    "\n",
    "Following are descriptions of the two datasets with which you will work.\n",
    "\n",
    "<b><u>Audit Analytics</u></b>  \n",
    "The *Audit Analytics* database tracks the fees charged by auditing firms. The dataset contains one row per client per year. For example, there is one row for Microsoft's 2018 audit fees. \n",
    "\n",
    "<b><u>Compustat</u></b>  \n",
    "The *Compustat* database tracks companies' accounting fundamentals. *Compustat* contains one row per company per fiscal year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 - Loading and Cleaning the Audit Analytics Dataset (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Audit Analytics database contains many columns and we downloaded only a subset. Your raw dataset, *AuditAnalytics.txt*, contains these columns:\n",
    "\n",
    "| Column             | Description                                                       |\n",
    "|--------------------|-------------------------------------------------------------------|\n",
    "| AUDITOR_FKEY       | A unique identifier for each auditor                              |\n",
    "| AUDIT_GIG_KEY      | A unique identifier for each audit engagement                     |\n",
    "| FISCAL_YEAR        | The fiscal year for this client and this row of data              |\n",
    "| FISCAL_YEAR_ENDED  | The date on which this client's fiscal year ends                  |\n",
    "| AUDIT_FEES         | Fees charged by the auditor for the audit                         |\n",
    "| NON_AUDIT_FEES     | *No description given in the database documentation*              |\n",
    "| TOTAL_FEES         | Total fees paid by the client to the auditor in this fiscal year  |\n",
    "| AUDIT_RELATED_FEES | *No description given in the database documentation*              |\n",
    "| OTHER_FEES         | *No description given in the database documentation*              |\n",
    "| AUDITOR_NAME       | Name of the auditing firm                                         |\n",
    "| COMPANY_FKEY       | EDGAR Central Index Key (CIK): a unique identifier for the client |\n",
    "| BEST_EDGAR_TICKER  | The client's stock ticker                                         |\n",
    "| NAME               | The client's name                                                 |\n",
    "| SIC_CODE_FKEY      | 4-digit industry classifier code                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.1 - Imports (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and Numpy, as you will use these throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2 - Load raw data file, *AuditAnalytics.txt* (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file *AuditAnalytics.txt* contains data from fiscal year 2018. We chose 2018 because it is the last full fiscal year before the COVID-19 pandemic. \n",
    "\n",
    "The data file contains __*tab-delimited*__ data. This is like CSV data, but uses tabs to separate the columns instead of commas. You can view this file in Excel if that will help you as you work with it.\n",
    "\n",
    "---\n",
    "\n",
    "* Use the Pandas `read_csv` function to load this tab-delimited data into a Pandas data frame. \n",
    "* Use a meaningful name for your data frame as you will create other data frames later.\n",
    "* *You must tell the `read_csv` function that your dataset is tab-delimited. Look up the help for this function and figure out how to do this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.3 - Drop unneeded columns (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains some extraneous columns. Drop the columns `SIC_CODE_FKEY` and `BEST_EDGAR_TICKER` as we will get this information from Compustat later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.4 - Filter to 2018 fiscal year (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset should only contain data for fiscal year 2018. \n",
    "1. Verify that the dataset contains only 2018 data. Write some code in the cell below that demonstrates this.\n",
    "2. If there are rows for other fiscal years, drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.5 - Date conversion (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the values in the `FISCAL_YEAR_ENDED` column. Write code that shows us whether they contain valid Pandas dates. If not, convert them to Pandas dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.6 - Descriptive stats of audit fees (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required:** Use the Pandas `describe` method to compute descriptive statistics on the `AUDIT_FEES` column.\n",
    "\n",
    "**Optional:** The output will be in scientific notation. If you want to make the output easier to read, append this method to your call to the `describe` method. It will format the numbers with commas and without decimals.  \n",
    "`.map(lambda x: f'{x:,.0f}')`  \n",
    "This is optional and intended to help you. If you are having difficulty with it, just ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.7 - Truncating the data (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are some large audit fees and some small ones. While the large fees might be considered outliers, they are likely legitimate numbers and should *not* be discarded. For example, it does not make sense to discard rows for large companies like Amazon and General Motors. However, data from very small companies is often \"noisy\"  and we should consider discarding such data.\n",
    "\n",
    "* Compute the 5th percentile value of the `AUDIT_FEES` column. \n",
    "* Print this 5th percentile value using the `print` function.\n",
    "* Filter out / remove all rows where the audit fee is strictly less than the 5th percentile value. Note: strictly less (<) does *not* mean less than or equal to (<=)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.8 - Spot checks (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the data makes sense. Search the data and write code that displays or prints the following:\n",
    "1. Which firm audited Ford Motor Company in 2018?\n",
    "2. How much did Ford pay in audit fees (AUDIT_FEES)?\n",
    "3. Which firm audited Illinois Tool Works in 2018?\n",
    "4. How much did ITW pay in audit fees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.9 - Non-unique company identifiers (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `COMPANY_FKEY` contains a unique company (client) identifier. Since we are working with data for one year (2018), there should only be one row per company. However, if you check, you will find that there are several repeated `COMPANY_FKEY` values. Verify this. Write code that demonstrates that there are some non-unique `COMPANY_FKEY` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.10 - Deleting non-unique company identifiers (11 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why might there be non-unique values of `COMPANY_FKEY`? One explanation is that some companies changed auditing firms in the middle of the year and Audit Analytics reports the fees for the former and current auditor. Another explanation is that an auditor performed multiple engagements at the same client (e.g., consulting work) and for some reason this is reported in separate rows. \n",
    "\n",
    "Data is never perfect, and data analysis often requires that you clean the data in imperfect ways. Our strategy is this. If a `COMPANY_FKEY` is repeated, then we will keep the row that contains the highest value of AUDIT_FEES. For example, say that `COMPANY_FKEY` 17 is repeated 3 times. In one row, AUDIT_FEES is 10. In the next row, AUDIT_FEES is 20, and in the third row, AUDIT_FEES is 30. You should drop the first two rows and only keep the third row with AUDIT_FEES of 30.\n",
    "\n",
    "---\n",
    "\n",
    "You will do this in stages. First, for each `COMPANY_FKEY`, compute the maximum amount of `AUDIT_FEES` paid. Write the code for this first step in the code cell below.\n",
    "\n",
    "*Hint:* use a pivot table, and save the pivot table as `dfMax`. Then rename the `AUDIT_FEES` column in `dfMax` to `Max_Audit_Fees`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will merge `dfMax` with your Audit Analytics data frame. We did not teach you how to merge data this semester so you will need to teach yourself the basics (and you will learn more about merging data next semester in ACCY 575). \n",
    "\n",
    "Here's a simple example to help you get started. Consider this data frame containing some information about pets:\n",
    "\n",
    "|    |   key | Type   |   Age |\n",
    "|---:|------:|:-------|------:|\n",
    "|  0 |     1 | cat    |     4 |\n",
    "|  1 |     2 | dog    |     9 |\n",
    "|  2 |     3 | bird   |     3 |\n",
    "\n",
    "Now say there is another data frame with related information:\n",
    "\n",
    "|    |   key | name    |\n",
    "|---:|------:|:--------|\n",
    "|  0 |     1 | Fluffy  |\n",
    "|  1 |     3 | Tweetie |\n",
    "|  2 |     5 | Spike   |\n",
    "\n",
    "\n",
    "If we merge these two data frames on the column named \"key\" with an inner join, we will get this data frame:\n",
    "\n",
    "|    |   key | Type   |   Age | name    |\n",
    "|---:|------:|:-------|------:|:--------|\n",
    "|  0 |     1 | cat    |     4 | Fluffy  |\n",
    "|  1 |     3 | bird   |     3 | Tweetie |\n",
    "\n",
    "For the rows where the keys matched (keys 1 and 3), the merge appended the columns from both data frames into the resulting data frame. If a key is only in one of the two data frames, its row will not appear in the merged data frame.\n",
    "\n",
    "---\n",
    "\n",
    "In the cell below, write code to merge `dfMax` with your Audit Analytics data frame. We strongly suggest that you use the [pd.merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html) function. Use an inner join, and join on the `COMPANY_FKEY` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, filter the merged data frame so that you keep rows where the audit fee is equal to the maximum audit fee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if our strategy worked. Check again whether there are any repeated COMPANY_FKEY values. If so, print those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are still a few repeated `COMPANY_FKEY` values. Let's ignore those and proceed. It will add some noise to our analysis, but hopefully not much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 - Loading and Cleaning the Compustat Dataset (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Compustat database contains hundreds of columns and we downloaded only a subset. Your raw dataset, *Compustat.txt*, contains these columns:\n",
    "\n",
    "| Column | Description |\n",
    "| ------ | ----------- |\n",
    "| GVKEY | A unique identifier for each company |\n",
    "| DATADATE | The reporting date (fiscal year end date) |\n",
    "| FYEAR | Fiscal year for this row |\n",
    "| INDFMT | Industry format (INDL for industrial, FS for financial services) |\n",
    "| CONSOL | Level of consolidation |\n",
    "| POPSRC | Population source (D for domestic (U.S. based) or I for international) |\n",
    "| DATAFMT | Data format |\n",
    "| TIC | Stock ticker symbol |\n",
    "| CONM | Company name |\n",
    "| CURCD | Currency code |\n",
    "| FYR | Fiscal year end month (i.e., 1 for January, 2 for February) |\n",
    "| ACT | Current assets (in millions of US dollars) |\n",
    "| AT | Total assets (in millions of US dollars) |\n",
    "| CEQ | Common equity  (in millions of US dollars) |\n",
    "| IB | Income before extraordinary items (in millions of US dollars) |\n",
    "| INVT | Inventories, total (in millions of US dollars) |\n",
    "| INVWIP | Inventories, work-in-process (in millions of US dollars) |\n",
    "| LCT | Current liabilities (in millions of US dollars) |\n",
    "| LT | Total liabilities (in millions of US dollars) |\n",
    "| NI | Net income (in millions of US dollars) |\n",
    "| RECT | Receivables, total (in millions of US dollars) |\n",
    "| REVT | SALE plus other operating revenues (in millions of US dollars) |\n",
    "| SALE | Gross sales less cash discounts, trade discounts, returns, and allowances (in millions of US dollars) |\n",
    "| CIK | Central Index Key (CIK) is the SEC's unique identifier for corporations and individuals who have filed disclosures with the SEC |\n",
    "| COSTAT | Company status (A for active, I for inactive) |\n",
    "| SIC | Standard industry classification code |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.1 - Load raw data file, *Compustat.txt* (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the Pandas `read_csv` function to load the file *Compustat.txt*, which contains tab-delimited data, into a Pandas data frame.\n",
    "* Use a meaningful name for your data frame as you will create other data frames later.\n",
    "* *You must tell the `read_csv` function that your dataset is tab-delimited. Look up the help for this function and figure out how to do this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.2 - Drop unneeded columns (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains many extraneous columns. Drop the columns `INDFMT`, `CONSOL`, `POPSRC`, `DATAFMT`, `CURCD`, and `COSTAT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.3 - Filter to 2018 fiscal year (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Compustat data file contains multiple fiscal years (you may check if you wish). Since we will eventually merge Compustat with Audit Analytics, we only want 2018 Compustat data. Therefore, filter the Compustat dataset so it only contains data for fiscal year 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the filter, make a copy of your data frame by modifying and running the code cell below. For example, if your data frame is named `df`, run the command `df = df.copy()`. Don't worry about why. Just trust us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.4 - Date conversion (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might need to use the `DATADATE` field later, but it is currently stored as a string. Convert the column to valid Pandas dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.5 - Dealing with missing values (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our primary identifier in this dataset is the `CIK` column. We must therefore impose the requirement that `CIK` is not missing. Drop any rows in which the `CIK` column has a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost about 2,000 rows out of about 9,000 when we dropped those rows! This is common when working with such data. Many small and privately-held companies, and many hedge funds, do not file reports with the SEC and may lack an identifier.\n",
    "\n",
    "---\n",
    "\n",
    "We will use SIC codes in a moment. Before we do, let's drop rows with missing values in the `SIC` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.6 - Dealing with data types (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check, you will find that Pandas has stored storing the CIK and SIC columns as floats. However, these values cannot contain fractional amounts and therefore it is better to store them as integers. Convert these two columns to the numpy int64 type (`np.int64`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.7 - Excluding some industries (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing data analyses such as ours, many researchers and analysts exclude data for companies in the financial services, insurance, and real estate industries. Companies in these industries have very different accounting practices than other companies, and hence their accounting numbers are not comparable.\n",
    "\n",
    "A common way to identify financial, insurance, and real estate companies is by SIC codes. SIC stands for \"standard industrial classification\" and is a taxonomy developed by various governments to classify companies. Go to [this website](https://siccode.com/) and determine the *range* of SIC codes that you want to exclude from our dataset. Be careful when reading this website! Ignore anything about NAICS (an alternative to SIC). Also, SIC codes are 4-digit codes. Keep that in mind as you interpret the information at the SIC website.\n",
    "\n",
    "---\n",
    "\n",
    "Write code to exclude financial and insurance companies from the Compustat data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost many rows! Looks like there were many financial companies in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.8 - Dealing with missing values, part 2 (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up our data some more. If a company does not report values in some critical columns (like total assets) then we should assume the data is suspect and drop that row.\n",
    "\n",
    "Remove rows with missing values in any of these columns:\n",
    "* Total assets\n",
    "* Common equity\n",
    "* Income before extraordinary items\n",
    "* Total liabilities\n",
    "* Net income\n",
    "* Revenues\n",
    "* Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.9 - Dealing with zero and negative values (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just removed rows with missing values in critical columns. Now let's remove rows with zero or negative values in certain columns. Zero and negative values might be legitimate, but companies with negative values in these columns are likely very different than other companies and might skew our analysis.\n",
    "\n",
    "Drop any rows with zero or negative numbers in any of these columns:\n",
    "* Total assets\n",
    "* Total liabilities\n",
    "* Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.10 - Dealing with missing values, part 3 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many companies do not report certain line items. For example, retailers do not have work-in-process inventories so they do not report this. Thus, some companies will have missing values in certain columns. Let's fill in those missing values with zeroes.\n",
    "\n",
    "In the following columns, replace missing values with zeros:\n",
    "* Current assets\n",
    "* Inventories\n",
    "* Work-in-process inventories\n",
    "* Current liabilities\n",
    "* Receivables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.11 - Dealing with units (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compustat data is in millions but Audit Analytics data reports actual amounts. Since we will soon merge this data, let's put all numbers on the same scale.\n",
    "\n",
    "Convert all Compustat columns that are in millions to actual amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 - Merging the Audit Analytics and Compustat Datasets (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should have two data frames, one containing cleaned Audit Analytics data, and the other containing cleaned Compustat data. See problem 1.10 for some guidance about merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3.1 - Setting up the merge (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your Audit Analytics data frame, there is a column named `COMPANY_FKEY`. Rename it to `CIK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3.2 - Merge the data frames (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the Audit Analytics and Compustat datasets using the CIK column.\n",
    "\n",
    "Hints: \n",
    "* We strongly recommend that you use the Pandas merge function [pd.merge](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html).\n",
    "* Use an inner join.\n",
    "* Merge on the CIK column.\n",
    "* Use the Audit Analytics data frame as the \"left\" and Compustat as the \"right\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3.3 - Save to Excel (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, you will need to load your data into Tableau for analysis. Therefore, save the merged data frame to an Excel file. Use the keyword argument `index=False` when you save to Excel. That will tell Pandas not to write the index to the Excel file and will make it easier to work with the data in Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 Analyzing the Data (45 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Tableau for our analysis. Load the Excel file that you just saved into Tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.1 - How many clients audited by each firm? (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Make a bar chart showing the number of clients audited by each auditing firm. \n",
    "* The bars should be horizontal.\n",
    "* Sort the bars in descending order.\n",
    "* Label each bar with the number of clients audited by that firm.\n",
    "* Name the worksheet \"Problem 4.1\"\n",
    "\n",
    "---\n",
    "\n",
    "In the caption for this worksheet, answer these questions:\n",
    "1. Are the \"Big 4\" actually the \"Big 4\"? Do these 4 firms have the most clients?\n",
    "2. Who are the fifth and sixth largest firms, by number of clients?\n",
    "3. What is the market share of the Big 4 (in total), as measured by number of clients? In other words, what percentage of companies in the dataset are audited by the Big 4? You might need to do this with a calculator, or in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.2 - Total audit fees collected by each firm (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Make a bar chart showing the total audit fees collected by each auditing firm. \n",
    "* The bars should be horizontal.\n",
    "* Sort the bars in descending order.\n",
    "* Label each bar with the total fees collected by that firm.\n",
    "* Format the labels in currency format, with zero decimal places.\n",
    "* Name the worksheet \"Problem 4.2\"\n",
    "\n",
    "---\n",
    "\n",
    "In the caption for this worksheet, answer these questions:\n",
    "1. Does the firm with the most clients collect the most fees?\n",
    "2. What is the market share of the Big 4, as measured by revenues? In other words, what percentage of total audit revenue in the dataset is collected by the Big 4? You might need to do this with a calculator, or in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.3 - Average audit fees collected by each firm (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a bar chart showing the *average* audit fees per client collected by each auditing firm. \n",
    "* The bars should be horizontal.\n",
    "* Sort the bars in descending order.\n",
    "* Label each bar with the average fees collected by that firm.\n",
    "* Format the labels in currency format, with zero decimal places.\n",
    "* Name the worksheet \"Problem 4.3\"\n",
    "\n",
    "---\n",
    "\n",
    "In the caption for this worksheet, answer these questions:\n",
    "1. Are Grant Thornton and BDO still in 5th and 6th position? \n",
    "2. Speculate on how an auditing firm like *Macias, Gini, & O'Connell*, with relatively few clients, might collect such high revenues per client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.4 - Company size as a driver of audit fees, part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin to examine the drivers of audit fees. A common finding in accounting research is that audit fees are higher for larger companies. This makes sense. Amazon should pay more to their auditor than a small company. If we do not find that company size is positively correlated with audit fees, we would be surprised and would question the integrity of our data. In this project, we will measure a company's size by its total assets. This is a common measure in research; another common measure is revenues.\n",
    "\n",
    "Even though this analysis may sound straightforward, you are about to see that there are some challenges when working with this data. In this problem, we will examine audit fees and company size (as measured by total assets). In the next problem, we will check whether they are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem 4.4 (a) -- (5 points)\n",
    "Make a histogram of audit fees in Tableau. You may use the default bin size. Name the worksheet \"Problem 4.4 (a)\".\n",
    "\n",
    "---\n",
    "\n",
    "Answer these questions in the caption:\n",
    "1. You have seen histograms like this before. How do you interpret this histogram? What does it tell you about your audit fee data?\n",
    "2. What is the range of fees in the tallest bin?\n",
    "3. Is this histogram what you expect? In other words, does the shape of this histogram surprise you? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem 4.4 (b) -- (3 points)\n",
    "A common measure of company size is total assets. Make a histogram of total assets in Tableau. You may use the default bin size. Name the worksheet \"Problem 4.4 (b)\".\n",
    "\n",
    "---\n",
    "\n",
    "Answer this question in the caption: is this histogram consistent with the previous one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Problem 4.4 (c) -- (4 points)\n",
    "Filter the histogram from 4.4(b) so that it only includes companies with total assets of less than \\\\$10 billion. Set the bin size to \\\\$100 million. Name the worksheet \"Problem 4.4 (c)\".\n",
    "\n",
    "Be careful! Did your histogram for 4.4(b) change? If so, fix it so the histograms for parts b and c are independent.\n",
    "\n",
    "---\n",
    "\n",
    "Answer these questions in the caption: \n",
    "1. Does the pattern from 4.4(b) persist?\n",
    "2. How many companies are in the first bin?\n",
    "3. What is the range of the first bin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.5 - Company size as a driver of audit fees, part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will investigate the correlation between audit fees and company size (as measured by total assets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem 4.5 (a) -- (3 points)\n",
    "* Make a scatter plot of audit fees (y-axis) versus total assets (x-axis) in Tableau. \n",
    "* Add a trend line.\n",
    "* Make the markers as small as possible.\n",
    "* Name the worksheet \"Problem 4.5 (a)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem 4.5 (b) -- (8 points)\n",
    "The scatter plot in 4.5(a) reveals an upward trend, but the graph is messy. The trend line has a good fit (R-squared is above 0.5), but the large range of the data makes it difficult to see a pattern. Also, there is a significant overplotting problem.\n",
    "\n",
    "Throughout the semester, when we encountered data with large ranges like this, we filtered it to a small range. However, doing so here would be problematic since such filtering would remove many \"blue chip\" clients and disproportionately impact our inferences about the Big 4, who tend to audit large companies.\n",
    "\n",
    "A common way of dealing with data with large ranges is to change the scale of the axes. Let's do that and then understand why it is helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tableau:\n",
    "* Duplicate the worksheet titled \"Problem 4.5 (a)\". When you do, you will see a new worksheet titled \"Problem 4.5 (a) (2)\". Rename that to \"Problem 4.5 (b)\".\n",
    "* Remove the trend line.\n",
    "* Right-click on the x-axis and click **Edit Axis...** Check the box next to the word *Logarithmic*.\n",
    "* Repeat the previous step for the y-axis (in other words, make the y-axis logarithmic).\n",
    "\n",
    "---\n",
    "\n",
    "Look at that! The data looks very different! It is the exact same data. We have not changed the data in any way. We are just displaying it differently. Look closely at the tick marks for the x-axis. They should be powers of 10 (e.g., 1, 100, 1000). On a logarithmic scale, every tick mark on an axis is 10 times larger than the last tick mark! Logarithmic scales are often used when working with data that has a wide range as it allows us to easily visualize such data. We have solved the clustering and overplotting problems in the previous problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the caption, answer these questions:\n",
    "1. Does the graph show a relationship between fees and assets?\n",
    "2. Does the relationship appear \"stronger\" than that in problem 4.5(a)?\n",
    "\n",
    "---\n",
    "\n",
    "Now do the following:\n",
    "* Add a trend line to this graph. When you do, the trend line might look weird, like a hockey stick. That's because a line, when plotted on a logarithmic scale, no longer appears to be a line.\n",
    "* Click on the trend line and click Edit.\n",
    "* You will see a list of options: linear, logarithmic, exponential, power, polynomial. Try each one. Choose the one that looks the best to you.\n",
    "\n",
    "---\n",
    "\n",
    "If you chose the Power option, your trend line will look like a line. If you hover over the trend line, you will see its equation. The equation will look like $Audit Fees = a \\cdot {AT}^b$, where $a$ and $b$ are numbers. \n",
    "\n",
    "What this tells us is that fees equal a constant times assets raised to a power. The exponent should be close to 0.5, so basically we are taking the square root of assets. In other words, as assets go up, fees increase by the square root of assets. Note that our trend line equation is <i><u>not</u></i> a linear equation. Instead, it shows that as company size increases, the rate at which fees increase diminishes and levels off. This makes economic sense. As a company grows from small to mid-size, the complexity of the audit will increase dramatically. As a large company (like Apple) grows, the extra work done by the auditor will grow, but not as much as it would from a small to a medium company. The auditor will benefit from an economy of scale.\n",
    "\n",
    "---\n",
    "\n",
    "In the caption, answer this question:  \n",
    "3. Use the trend line equation to predict the audit fees for a company with \\\\$1 billion in total assets. You may need to use a calculator for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4.6 - Risk as a driver of audit fees (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will investigate the relationship between audit fees and the risk of an audit engagement. Whenever an auditor agrees to audit a client, they assume some risk. If the auditor does not catch mistakes or fraud, investors can sue the auditor. Accounting research has found that inventory is a measure of risk. The reason is that it takes effort to audit inventories; often, physical counts must be taken in multiple locations and then reconciled with the client's accounting records. This process dramatically increases the auditor's workload and hence audit fees. Let's confirm this hypothesis in our data.\n",
    "\n",
    "Many companies, such as those that provide services, do not have inventory. Or if they do, inventory is immaterial and reported as 0. Therefore, let's focus on two industries that have significant inventory: retail and manufacturing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tableau:\n",
    "* Create a \"calculated field\" called \"Industry\". \n",
    "    - The value of this field should be \"Retail\" if the SIC code for a row matches:\n",
    "        * \"Building Materials, Hardware, Garden Supplies, and Mobile Home Dealers\"\n",
    "        * \"General Merchandise Stores\"\n",
    "        * \"Food Stores\"\n",
    "        * \"Automotive Dealers and Gasoline Service Stations\"\n",
    "        * \"Apparel and Accessory Stores\"\n",
    "        * \"Home Furniture, Furnishings, and Equipment Stores\"\n",
    "    - The value of this field should be \"Manufacturing\" if the SIC code for a row is in the range of \"Manufacturing\". \n",
    "    - The value of this field should be \"Other\" for all other SIC codes. \n",
    "    - In other words, the \"Industry\" field can only have 3 values, \"Retail\", \"Manufacturing\", or \"Other\".\n",
    "    - Look [here](https://siccode.com/) for SIC codes.\n",
    "* Now create two scatter plots, on the same worksheet, of Audit Fees (y-axis) versus Inventory (x-axis).\n",
    "    - There should be one graph for Manufacturing and one for Retail. They should be stacked (Manufacturing on top of Retail).\n",
    "    - Do NOT show a graph for \"Other\" industries.\n",
    "    - Make the markers as small as possible.\n",
    "    - Change the scale for both axes to logarithmic\n",
    "    - Add trend lines to both graphs; use the Power option.\n",
    "    - Name this worksheet \"Problem 4.6\"\n",
    "    \n",
    "---\n",
    "\n",
    "You have two trend lines, one for manufacturing and one for retail. Use the equations for the two trend lines to answer these questions in the worksheet caption. Remember that you can see the equations for the trend linse by hovering over them with your mouse.\n",
    "\n",
    "1. Use the trend line from the manufacturing graph to calculate the predicted audit fees for a manufacturer with inventories of \\\\$1 billion. You may need to use a calculator.\n",
    "2. Use the trend line from the retail graph to calculate the predicted audit fees for a retailer with inventories of \\\\$1 billion. You may need to use a calculator.\n",
    "3. Compare the two numbers and speculate on why one is higher than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Auditor Tenure (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auditor tenure is the length of time for which an auditor has audited a client company. Some people argue that longer auditor tenure can lead to a less independent auditor because the auditor has developed a relationship with their client over time. Indeed, audit partners must rotate off of their public audit clients in order to avoid any independence concerns. Others have investigated this possibility and found that auditor tenure is not associated with lower quality audits. The debate about auditor tenure continues. \n",
    "\n",
    "In this problem you will use annual reports to determine the auditor and auditor tenure for each company. The Excel file *GatherAuditorData.xslx* contains a list of the top 20 companies in the Fortune 500. Open that file in Excel now and scan it. You will see 6 columns:\n",
    "\n",
    "* Rank\n",
    "* Company\n",
    "* Ticker\n",
    "* AuditorName\n",
    "* AuditorSince\n",
    "* NumYearsAsAuditor\n",
    "\n",
    "The columns `AuditorName`, `AuditorSince`, and `NumYearsAsAuditor` are empty and you will populate them. To do this, you will write code that opens each annual report (PDFs), extracts the text, searches the text for relevant information, and adds this information to a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.1 - Read the Excel file (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Excel file *GatherAuditorData.xlsx* into a data frame. Name the data frame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the following cell to populate the empty `AuditorName` column with empty strings. This will prevent errors later in this problem.\n",
    "\n",
    "If your data frame has a different name than df, please modify the cell below before running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AuditorName'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.2 - Extract Auditor info, populate data frame (32 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20 PDFs that accompany this project, one for each company listed in the Excel file. The names of the PDFs correspond to the ticker symbols of the companies in the Excel file. Write a loop that iterates over these PDFs and does the following:\n",
    "\n",
    "For each PDF:\n",
    "1. Open the PDF file\n",
    "2. Extract the text for all pages\n",
    "3. Within the text of each PDF, there is a sentence in the auditor's letter that states the year in which the auditor began auditing that company. The sentence is structured differently in every file, but it always ends with \"*auditor since XXXX*\", where *XXXX* is a 4-digit year. Use this knowledge to search the PDF for this piece of text. Extract the year, and use it to complete the columns `AuditorSince` and `NumYearsAsAuditor`.\n",
    "4. Search each annual report for the names of the Big 4 auditors and add the auditor name to the `AuditorName` column.\n",
    "5. Convert the `AuditorSince` and `NumYearsAsAuditor` columns of the data frame to integer.\n",
    "6. Ensure the resulting dataframe is sorted by rank and display/print the data frame so we can see the result.\n",
    "\n",
    "Hints:\n",
    "* Use the `PyPDF2` library.\n",
    "* Use the Python regular expressions library, `re`.\n",
    "* The Python regular expressions library has a method `re.findall` that returns a list of all matches of a regular expression within a string.\n",
    "* To update data in a single cell in your dataframe, use the `.at` method.\n",
    "* Consider setting the dataframe index to the Ticker column. Note that this is not mandatory. It is possible to do this problem without doing this.\n",
    "\n",
    "Finally, note that this task might take some time to run on your computer. Don't be surprised if it takes 10 minutes to go through all 20 PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code in this cell\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1beb67598d5bd82b7eda52a5a65977912fb67dfd17090e301c50452747283846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
